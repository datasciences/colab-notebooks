{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark-basic-linear-regression-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOipYIdN6NlAryvv6tMqdUH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/spark/pyspark_basic_linear_regression_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OFzWJGBn9pf",
        "colab_type": "text"
      },
      "source": [
        "# PySpark Linear Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64exhWJqoTLf",
        "colab_type": "text"
      },
      "source": [
        "## Setup PySpark instance\n",
        "\n",
        "To run spark in Colab, we need to first install all the dependencies in Colab environment i.e. Apache Spark 2.3.2 with hadoop 2.7, Java 8 and Findspark to locate the spark in the system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcsX_uOvn6Sh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "cellView": "form",
        "outputId": "aaad46ce-9c8c-4910-8bae-407232162420"
      },
      "source": [
        "#@title ### Setup PySpark instance\n",
        "#@markdown To run spark in Colab, we need to first install all the dependencies in Colab environment i.e. Apache Spark 2.3.2 with hadoop 2.7, Java 8 and Findspark to locate the spark in the system.\n",
        "\n",
        "#@markdown **Uppon successful completion of this cell a ``SparkSession`` context named ``spark`` will be available to interact with the service.**\n",
        "\n",
        "#@markdown Creating multiple ``SparkSession`` or ``SparkContext`` object could \n",
        "#@markdown cause issues. If you need to get a reference to the context it is \n",
        "#@markdown recommended to use ``SparkSession.builder.getOrCreate()``.\n",
        "\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "import findspark\n",
        "# environment variables\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "os.environ['SPARK_HOME'] = 'spark-2.4.5-bin-hadoop2.7'\n",
        "# check installation\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2546b955bc33:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f00d251c6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtFmZSeItCyF",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression Model\n",
        "\n",
        "\n",
        "Download the Boston housing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCVHdVTqtCTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/martin-fabbri/colab-notebooks/master/data/boston.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sawhmx1ErQwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = spark.read.csv('boston.csv', inferSchema=True, header =True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9umKxZcuXDO",
        "colab_type": "text"
      },
      "source": [
        "``SparckSession`` has an attribute called ``catalog`` which list all teh data inside te cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5tUljyFu0g-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "add7f670-2bbf-432b-e0e9-b8835b3cf795"
      },
      "source": [
        "spark.catalog.listTables()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLZzyBuNrQt_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "38dd61a4-918f-4fea-fedc-32e149ec534b"
      },
      "source": [
        "dataset.printSchema()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- CRIM: double (nullable = true)\n",
            " |-- ZN: double (nullable = true)\n",
            " |-- INDUS: double (nullable = true)\n",
            " |-- CHAS: integer (nullable = true)\n",
            " |-- NX: double (nullable = true)\n",
            " |-- RM: double (nullable = true)\n",
            " |-- AGE: double (nullable = true)\n",
            " |-- DIS: double (nullable = true)\n",
            " |-- RAD: integer (nullable = true)\n",
            " |-- TAX: double (nullable = true)\n",
            " |-- PTRATIO: double (nullable = true)\n",
            " |-- B: double (nullable = true)\n",
            " |-- LSTAT: double (nullable = true)\n",
            " |-- MEDV: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp3KL_6qwWj7",
        "colab_type": "text"
      },
      "source": [
        "Next step is to convert all the features from different columns into a single column and let's call this new vector column as 'Attributes' in the outputCol."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USGBh08RrQq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "65250992-910b-45f9-b97e-f4c3edf7185b"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(inputCols=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NX', \\\n",
        "                                        'RM', 'AGE', 'DIS', 'RAD', 'TAX', \\\n",
        "                                        'PTRATIO', 'B', 'LSTAT'], \n",
        "                            outputCol='Attributes')\n",
        "output = assembler.transform(dataset)\n",
        "\n",
        "#input vs output\n",
        "finalized_data = output.select('Attributes', 'MEDV')\n",
        "finalized_data.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+\n",
            "|          Attributes|MEDV|\n",
            "+--------------------+----+\n",
            "|[0.00632,18.0,2.3...|24.0|\n",
            "|[0.02731,0.0,7.07...|21.6|\n",
            "|[0.02729,0.0,7.07...|34.7|\n",
            "|[0.03236999999999...|33.4|\n",
            "|[0.06905,0.0,2.18...|36.2|\n",
            "|[0.02985,0.0,2.18...|28.7|\n",
            "|[0.08829,12.5,7.8...|22.9|\n",
            "|[0.14455,12.5,7.8...|27.1|\n",
            "|[0.21124,12.5,7.8...|16.5|\n",
            "|[0.17004,12.5,7.8...|18.9|\n",
            "|[0.22489,12.5,7.8...|15.0|\n",
            "|[0.11747,12.5,7.8...|18.9|\n",
            "|[0.09378,12.5,7.8...|21.7|\n",
            "|[0.62976,0.0,8.14...|20.4|\n",
            "|[0.63796000000000...|18.2|\n",
            "|[0.62739,0.0,8.14...|19.9|\n",
            "|[1.05393,0.0,8.14...|23.1|\n",
            "|[0.7842,0.0,8.14,...|17.5|\n",
            "|[0.80271,0.0,8.14...|20.2|\n",
            "|[0.7258,0.0,8.14,...|18.2|\n",
            "+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOrq-iuj2wUT",
        "colab_type": "text"
      },
      "source": [
        "Our data vector defines two columns ``Attributes`` and ``MEDV``, input features and targer column respectively. Next, we should split our data training and test before fitting our data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-9Sprj0zaQi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "db88afab-ec49-4ec7-94e0-1d1c965b78df"
      },
      "source": [
        "train_data, test_data = finalized_data.randomSplit([0.8, 0.2])\n",
        "\n",
        "regressor = LinearRegression(featuresCol='Attributes', labelCol='MEDV')\n",
        "regressor = regressor.fit(train_data)\n",
        "pred = regressor.evaluate(test_data)\n",
        "pred.predictions.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+------------------+\n",
            "|          Attributes|MEDV|        prediction|\n",
            "+--------------------+----+------------------+\n",
            "|[0.0187,85.0,4.15...|23.1| 25.62529848996516|\n",
            "|[0.02055,85.0,0.7...|24.7|25.383395723957356|\n",
            "|[0.02543,55.0,3.7...|23.9| 27.95900238002728|\n",
            "|[0.02731,0.0,7.07...|21.6|25.421306443814338|\n",
            "|[0.0315,95.0,1.47...|34.9|30.239757246103377|\n",
            "|[0.03501999999999...|28.5|33.180222117817465|\n",
            "|[0.03768,80.0,1.5...|34.6|35.137993589186514|\n",
            "|[0.04297,52.5,5.3...|24.8|26.752497041852898|\n",
            "|[0.04301,80.0,1.9...|18.2|14.620407686959577|\n",
            "|[0.0456,0.0,13.89...|23.3|25.483724867444216|\n",
            "|[0.04819,80.0,3.6...|21.9|24.516677393482873|\n",
            "|[0.05187999999999...|22.5| 21.51696034676715|\n",
            "|[0.05497000000000...|19.0|20.681107473459594|\n",
            "|[0.05515,33.0,2.1...|36.1| 32.63034110467832|\n",
            "|[0.05602000000000...|50.0| 35.66183092150246|\n",
            "|[0.05646,0.0,12.8...|21.2|21.393845387141205|\n",
            "|[0.06076,0.0,11.9...|23.9|28.083840518530724|\n",
            "|[0.06211000000000...|22.9|21.105081530614935|\n",
            "|[0.06417,0.0,5.96...|18.9|23.484010703687687|\n",
            "|[0.06617,0.0,3.24...|19.3|20.637589821380125|\n",
            "+--------------------+----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2A7zfTGrQn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e2b3aef9-f85e-4e32-c843-70b96db433a5"
      },
      "source": [
        "#coefficient of the regression model\n",
        "coeff = regressor.coefficients\n",
        "\n",
        "#X and Y intercept\n",
        "intr = regressor.intercept\n",
        "\n",
        "print (\"The coefficient of the model is : %a\" %coeff)\n",
        "print (\"The Intercept of the model is : %f\" %intr)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The coefficient of the model is : DenseVector([-0.0966, 0.0466, 0.0558, 2.053, -18.3335, 3.9833, 0.0184, -1.2791, 0.2753, -0.0109, -0.9646, 0.0085, -0.5678])\n",
            "The Intercept of the model is : 34.019999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSsBsQ5DGDuG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "fa0e810f-e490-40c2-c434-efb474884771"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "eval = RegressionEvaluator(labelCol=\"MEDV\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "# Root Mean Square Error\n",
        "rmse = eval.evaluate(pred.predictions)\n",
        "print(\"RMSE: %.3f\" % rmse)\n",
        "\n",
        "# Mean Square Error\n",
        "mse = eval.evaluate(pred.predictions, {eval.metricName: \"mse\"})\n",
        "print(\"MSE: %.3f\" % mse)\n",
        "\n",
        "# Mean Absolute Error\n",
        "mae = eval.evaluate(pred.predictions, {eval.metricName: \"mae\"})\n",
        "print(\"MAE: %.3f\" % mae)\n",
        "\n",
        "# r2 - coefficient of determination\n",
        "r2 = eval.evaluate(pred.predictions, {eval.metricName: \"r2\"})\n",
        "print(\"r2: %.3f\" %r2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 4.779\n",
            "MSE: 22.841\n",
            "MAE: 3.330\n",
            "r2: 0.712\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}